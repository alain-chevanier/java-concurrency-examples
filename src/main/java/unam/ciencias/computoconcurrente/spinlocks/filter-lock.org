* BackoffLock
Essentilly the same as TTASLock, but when it fails to get the lock it backs off, which means it stop contending for the lock as there must be contention.

It improves performance compare to TTASLock, but sleep times are not portable across architectures or even computer capabilities.

* Queue Locks: AndersonLock (/ALock/)
[[file:TASLock.java][TASLock]], [[file:TTASLock.java][TTASLock]] and [[file:BackoffLock.java][BackoffLock]] do not only have poor performance on bus-based architectures, but they do not offer any fairness property, to solve both problems we can use a queue where theevel in the original description).
- Each thread goes through each level, and in each level before proceeding to the next level it needs to keep checking (spinning) while it is the last to arrive to the current level and if there are other threads in the same or a higher level.
- Pseudocode in the next code snippet:

#+begin_src python
# suppose thread ids go from 1 to N
N = 5 # any fixed number representing the number of threads
thread_level[N]
last_thread_to_arrive[N] # entries of this array must be volatile

lock_acquire():
  my_thread_id = get_thread_id()
  for level in 0..N:
    thread_level[my_thread_id] = level
    last_thread_to_arrive[level] = my_thread_id # Forcing cache coherency in this write is enough
    while last_thread_to_arrive[level] == my_thread_id
          and exist_other_thread_in_same_or_higher_level(my_thread_id, level):
      pass # keep spinning

lock_release():
  my_thread_id = get_thread_id()
  thread_level[my_thread_id] = -1 # NO_LEVEL,
  # NOTE: this write is eventually propagated as it does not force cache coherency,
  #   this might delay other threads a little but we make it to avoid cache invalidation
  #   storms on every write
#+end_src

Note: Implementation can be found at: [[file:FilterLock.java][FilterLock]] class.

You can run the test for the test from [[file:/src/test/java/unam/ciencias/computoconcurrente/spinlocks/FilterLockTest.java][FilterLockTest]] class to verify the implementation.

** Notes to avoid data races
It is important to avoid data races in this algorithm as a thread needs to know when other threads are in the same or higher levels, otherwise it will advance to the following level even when it is the victim of its current level.
To avoid data races we need to make sure that before we start spinning we force the caches to be coherent, in this case it is enough for the last write to be made on a volatile memory location to establish a /happens-before relationship/ which forces cache coherency. This means entries of the array ~last_thread_to_arrive~ must be ~volatile~, making entries of the array ~thread_level~ is not only unnecessary but it will also result in even worse performance as cache cohenrency will be forced when writing to this array.

** Notes about bus-base architecture performance
This algorithm has the same problem as /AndersonLock/ (/ALock/) as the arrays ~thread_level~ and ~last_thread_to_arrive~ are shared within the same cache line for several threads, and you notify other thread can proceed to the next level when it knows it is no longer the victim (only affected by one thread) of the level or when all other threads leave the CS (affected potentially by all other threads writes to ~thread_level~), therefor this algorith is really inefficient in terms of bus/cache usage as it depend potentially in what all other threads write to the shared memory.
